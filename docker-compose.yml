version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: rag_postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: rag_user
      POSTGRES_PASSWORD: rag_password
      POSTGRES_DB: rag_database
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U rag_user -d rag_database"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag_network

  qdrant:
    image: qdrant/qdrant:latest
    container_name: rag_qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag_network

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rag_backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # Application
      - APP_NAME=RAG Word Service
      - APP_VERSION=1.0.0
      - APP_HOST=0.0.0.0
      - APP_PORT=8000
      - DEBUG=True
      
      # OpenAI API
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_EMBEDDING_MODEL=text-embedding-3-small
      - OPENAI_LLM_MODEL=gpt-4o-mini
      
      # PostgreSQL (Docker internal network)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=rag_user
      - POSTGRES_PASSWORD=rag_password
      - POSTGRES_DB=rag_database
      
      # Qdrant (Docker internal network)
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_COLLECTION_NAME=documents
      
      # File Upload
      - MAX_FILE_SIZE_MB=10
      - ALLOWED_EXTENSIONS=.docx
      
      # RAG Settings
      - CHUNK_SIZE=1000
      - CHUNK_OVERLAP=100
      - TOP_K_RESULTS=3
      
      # LLM Settings
      - LLM_TEMPERATURE=0.7
      - LLM_MAX_TOKENS=1000
    
    volumes:
      - ./backend/uploads:/app/uploads
      - ./backend/logs:/app/logs
    
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    networks:
      - rag_network

networks:
  rag_network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  qdrant_data:
    driver: local